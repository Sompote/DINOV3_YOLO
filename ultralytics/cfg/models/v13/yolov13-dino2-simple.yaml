nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolov13n.yaml' will call yolov13.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024]   # Nano
  s: [0.50, 0.50, 1024]   # Small
  l: [1.00, 1.00, 512]    # Large
  x: [1.00, 1.50, 512]    # Extra Large

backbone:
  # [from, repeats, module, args]
  # Start with standard CNN layers
  - [-1, 1, Conv,  [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv,  [128, 3, 2]] # 1-P2/4
  - [-1, 1, Conv,  [256, 3, 2]] # 2-P3/8
  - [-1, 1, Conv,  [512, 3, 2]] # 3-P4/16
  
  # DINO2 enhancement layer - takes 512 channels, outputs 512 channels
  - [-1, 1, DINO2Backbone, ['dinov2_vitb14', True, 512]] # 4: DINO2 enhanced features
  
  # Continue with standard processing
  - [-1, 1, Conv,  [1024, 3, 2]] # 5-P5/32

head:
  # Use standard detection head with multi-scale features
  # Features from layers 2 (P3), 4 (P4-enhanced), and 5 (P5)
  
  # P5 to P4
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 6
  - [[-1, 4], 1, Concat, [1]] # 7: cat P5 with enhanced P4
  - [-1, 1, Conv, [512, 3, 1]] # 8: process concatenated features
  
  # P4 to P3  
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]] # 9
  - [[-1, 2], 1, Concat, [1]] # 10: cat with P3
  - [-1, 1, Conv, [256, 3, 1]] # 11: P3 output
  
  # P3 to P4
  - [-1, 1, Conv, [256, 3, 2]] # 12
  - [[-1, 8], 1, Concat, [1]] # 13: cat with P4
  - [-1, 1, Conv, [512, 3, 1]] # 14: P4 output
  
  # P4 to P5
  - [-1, 1, Conv, [512, 3, 2]] # 15
  - [[-1, 5], 1, Concat, [1]] # 16: cat with P5
  - [-1, 1, Conv, [1024, 3, 1]] # 17: P5 output
  
  # Detection heads
  - [[11, 14, 17], 1, Detect, [nc]] # 18: Detect(P3, P4, P5)